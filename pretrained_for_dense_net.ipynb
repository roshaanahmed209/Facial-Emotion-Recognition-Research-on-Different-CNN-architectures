{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "QM0hx1K1qDf9",
        "outputId": "e57a204f-f5cd-473d-996c-d2ec5fe47ffe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 24422 images belonging to 5 classes.\n",
            "Found 5937 images belonging to 5 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-a47b1679b7cc>:75: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "  6/764 [..............................] - ETA: 4:31:42 - loss: 2.2732 - accuracy: 0.2396"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a47b1679b7cc>\u001b[0m in \u001b[0;36m<cell line: 75>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m model.fit_generator(\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Limit to 1000 images per class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2911\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2912\u001b[0m         )\n\u001b[0;32m-> 2913\u001b[0;31m         return self.fit(\n\u001b[0m\u001b[1;32m   2914\u001b[0m             \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2915\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import DenseNet121\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# Define data directories\n",
        "train_dir = 'drive/MyDrive/images/train'\n",
        "validation_dir = 'drive/MyDrive/images/test'\n",
        "\n",
        "# Define parameters\n",
        "batch_size = 32\n",
        "image_size = (224, 224)\n",
        "num_classes = 5  # Change this according to your dataset\n",
        "\n",
        "# Data augmentation and normalization for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "# Normalization for validation\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create data generators with a limit of 1000 images per class\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    subset='training'  # Specify the subset for training data\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "# Load pre-trained DenseNet model (weights are downloaded automatically)\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False)\n",
        "\n",
        "# Add custom layers on top of the pre-trained model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Define new model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=min(1000, len(train_generator)),  # Limit to 1000 images per class\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=len(validation_generator)\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model.save('pretrained_densenet_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Define labels\n",
        "label = ['angry', 'happy', 'neutral', 'sad', 'surprise']\n",
        "\n",
        "# Function to extract features from image\n",
        "# Function to extract features from image\n",
        "def ef(image):\n",
        "    img = load_img(image, color_mode='rgb', target_size=(48, 48))  # Specify color_mode='rgb'\n",
        "    feature = np.array(img)\n",
        "    feature = feature.reshape(1, 48, 48, 3)  # Reshape to include three color channels\n",
        "    return feature / 255.0\n",
        "\n",
        "\n",
        "# Prediction and visualization\n",
        "image = 'drive/MyDrive/images/test/sad/22977.jpg'\n",
        "print(\"original image is of neutral\")\n",
        "img = ef(image)\n",
        "pred = model.predict(img)\n",
        "pred_label = label[np.argmax(pred)]\n",
        "print(\"model prediction is \", pred_label)\n",
        "\n",
        "# Display the image\n",
        "# Display the image\n",
        "plt.imshow(img[0])\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "Giaf2ILxrl9m",
        "outputId": "01d09a7b-7992-49d7-927a-048cba166729"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original image is of neutral\n",
            "1/1 [==============================] - 0s 181ms/step\n",
            "model prediction is  happy\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}